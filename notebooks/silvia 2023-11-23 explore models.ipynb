{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import TextConverter\n",
    "from haystack.nodes import PreProcessor\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.nodes import TransformersSummarizer\n",
    "from transformers import GenerationConfig\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
    "from haystack.nodes import EmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_dict = dict()\n",
    "text_converter_dict = dict() \n",
    "preprocessor_dict = dict()\n",
    "document_store_dict = dict()\n",
    "prompt_node_dict = dict()\n",
    "hf_access_token = os.getenv('access_token_huggingface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads\n",
    "embedding_models_list = [\n",
    "    'sentence-transformers/all-mpnet-base-v2',\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing pipeline: Save and load document store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "text_converter = TextConverter() # https://docs.haystack.deepset.ai/docs/file_converters\n",
    "text_converter_dict[iteration] = text_converter\n",
    "\n",
    "preprocessor = PreProcessor( # https://docs.haystack.deepset.ai/docs/preprocessor\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "  \tremove_substrings=None,\n",
    "    split_by=None, # Unit for splitting the document. Can be \"word\", \"sentence\", or \"passage\". Set to None to disable splitting.\n",
    "    split_length=200,\n",
    "    split_respect_sentence_boundary=True,\n",
    "    split_overlap=0,\n",
    "  \tmax_chars_check = 100000\n",
    ")\n",
    "preprocessor_dict[iteration] = preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def append_timestamp(string, ext=None):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "    if ext:\n",
    "        return f'{string}_{timestamp}.{ext}'\n",
    "    else:\n",
    "        return f'{string}_{timestamp}' \n",
    "\n",
    "index_filename = append_timestamp('journal_article_index')\n",
    "config_filename = append_timestamp('journal_article_config')\n",
    "faiss_filename = append_timestamp('faiss_document_store')\n",
    "path = '../data/testing_2023-11-23/'\n",
    "document_store = FAISSDocumentStore( # https://docs.haystack.deepset.ai/reference/document-store-api#faissdocumentstore\n",
    "    sql_url=f\"sqlite:///{path}{faiss_filename}.db\",\n",
    "    faiss_index_factory_str=\"Flat\"\n",
    "    )\n",
    "document_store_dict[iteration] = document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cead0343494d93b0217a93e4143236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51031b83d9648eab12590df8dea601e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5797eaa4394fce8a26c582bd2327ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63cb977f95d45ddb39f4c7e9bf64064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19465d7bf9ea4c4480ed3a0b9a5478a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc5bd0fb4b045b89f37541d697e4b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1775aa7222d4ac3b48b3fd93d5910bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f90656638cb400abe5d9beb45da3462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309e2bf76fb24cd6878d4bb2c8c69d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2398eba6027d440ca18531cc4cc87e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ded59662d24047be6ece20161c2fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110135acc8f041f5997cf9aceb4c6286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c0a5ed6c5940628bf6d04275b78602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1c3e586bff46bbb4df88e6322b9871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silvhua/solarathon/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "retriever = EmbeddingRetriever( # https://docs.haystack.deepset.ai/reference/retriever-api\n",
    "    document_store=document_store,\n",
    "    embedding_model=embedding_models_list[iteration - 1],\n",
    "    model_format=\"sentence_transformers\",\n",
    "    top_k = 100\n",
    ")\n",
    "retriever_dict[iteration] = retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting files: 100%|██████████| 1/1 [00:00<00:00, 128.63it/s]\n",
      "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 3350.08docs/s]\n",
      "Writing Documents: 10000it [00:00, 673048.56it/s]       \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0735718c824d09805666b1a91fa6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'documents': [<Document: {'content': 'High doses of anti-inflammatory drugs compromise muscle strength and hypertrophic adaptations to resistance training in young adults.\\n\\nDiscussion\\nThe interest in this study was spurred by the intriguing observation that while NSAIDs might have a negative impact on acute exercise responses (satellite cell activity, translational signalling and protein synthesis), previous human studies have failed to demonstrate a detrimental effect of NSAIDs on the development of muscle hypertrophy in response to chronic resistance training in young adults, possibly due to differences in drug dosage across studies. Accordingly, in the current study, healthy young men and women performed 8 weeks of supervised resistance training with concomitant high- or low-dose NSAID treatment. The major and novel findings were that 1) maximal overthe-counter doses of ibuprofen compromised resistance exercise-induced muscle hypertropy\\nindependent of training mode; 2) increases in muscle strength were attenuated by ibuprofen only when training was performed with maximal all-out repetitions; 3) while the resistance-training intervention resulted in several muscle molecular adaptations, the only marked difference across medical treatment was a significant ibuprofen-induced downregulation of the inflammatory cytokine IL-6 mRNA, compared with an upregulation in the ASA group. This is the first study showing that daily consumption of high doses of NSAIDs attenuates strength and muscle hypertrophic adaptations to resistance training in young healthy individuals. We acknowledge that a limitation of the current study was that we did not include a non-treated control group. However, the increase in muscle volume (7.5%) in the ASA group was of a similar, and expected, magnitude to that previously reported by our group20 and others.21,22 In the light of this, the magnitude of the reduction in muscle hypertrophy in response to the ibuprofen treatment was quite remarkable and, if anything, should the ASA treatment have had a small effect on the adaptive response, it would only have masked an even greater difference across groups than what is reported herein. Nonetheless, given the marked effect of ibuprofen and the fact that the increase in muscle size in the control group (0.14% per day) was of similar magnitude as the average rate of hypertrophy reported in past studies employing knee-extensor resistance training,23 we are confident that our data provide strong proof-of-principle evidence that the effect of NSAIDs on muscle adaptations to resistance exercise is dependent of the dose of intake. The rationale for using acetylsalicylic acid instead of ibuprofen as a low-dose comparator in the current study was based on the fact that when the drug is consumed orally, it undergoes substantial presystemic hydrolysis in the gut and liver before it enters the systemic bloodstream. As the drug will, however, encounter blood in the portal circulation, low doses of acetylsalicylic acid will exert its antiplatelet effect with no or limited effect on systemic targets such as peripheral tissue.1618 Consequently, the potential circulatory effects are factored out and we hypothesize that the negative effect of ibuprofen was due to muscle-specific COX inhibition rather than the antiplatelet effect achieved by both ibuprofen and low doses of acetylsalicylic acid.18,24 The results of the present study are in agreement with animal studies showing an inhibitory effect of COX inhibitors on muscle hypertrophy.8,9,25 They also agree with acute human data reporting attenuated protein synthesis,5 translational signalling13 and satellite cell activity11,12 in response to resistance training with concomitant high-dose NSAID administration. Our hypothesis of a dose-dependent effect is also supported by the only comparable training study in young healthy subjects.14 That particular study reported no effect of ibuprofen on muscle hypertrophy or strength gains after 6 weeks of training consisting of six sets of biceps curls 23 days week---------------1 . The drug dose was consumed on training days only, resulting in a total intake of 8001200 mg week---------------1 , 14 compared with 1200 mg per day in the current study. This indeed highlights the potential importance of drug dosage where, evidently, intake of maximal over-the-counter doses is potent enough to interfere with the normal hypertrophic development of 0.10.2% per day seen in the ASA group as well as in other studies employing conventional resistance-training programmes for the knee extensors.23 It is generally agreed that repeated increases in muscle protein synthesis following each exercise bout is the most important mechanism underlying training-induced muscle hypertrophy.26,27 Thus, it seems plausible to suggest that the main explanation for the clear attenuation of hypertrophy, which was evident in both training modes (FW and WS), was diminished prostaglandin production and hence decreased muscle protein synthetic response after each training session in the IBU group. Indeed, there is increasing evidence that COX and prostaglandins play an important role in regulating the molecular events controlling muscle hypertrophy. For example, C2C12 myotube diameter was shown to be regulated by PGF2a in an mTORdependent manner7 , and exercise-induced increases in p70S6K (downstream of mTOR) was blunted by ibuprofen treatment in the early hours following acute resistance exercise.13 In the current study, however, there were no group interactions for any of the target proteins examined, suggesting that the ibuprofenmodulating effect on muscle adaptations is not associated with differential expression of steady-state proteins in response to chronic training. Perhaps assessing satellite cell content,11 or the phosphorylation levels of translational signalling proteins in response to acute exercise,13 would have provided more mechanistic insights. We measured several key molecular markers for COX and prostaglandin-mediated metabolism, regulators of muscle growth and atrophy, and several cytokines and myokines that have been shown to regulate skeletal muscle protein metabolism and exercise adaptations.4 The most clear-cut molecular evidence for an effect of ibuprofen on peripheral muscle tissue was the marked drug effect on IL-6 mRNA, where levels in the ibuprofen group were downregulated despite a significant upregulation in the control group. The reduction of IL-6 in the ibuprofen group is coherent with previous studies suggesting PGE2 as a stimulator of IL-6 transcription in both human muscle28 and other cell types.29 It has previously been reported that the NSAID-modulating effects on muscle hypertrophy in older subjects were associated with lowered expression of IL-6 and subsequently MuRF-1, resulting in a more beneficial cellular environment for muscle growth.30 While our data are coherent with that of Trappe and colleagues regarding the expression of IL-6 in the ibuprofen-treated group (downregulated) compared to the control group (upregulated), the muscle hypertrophy data certainly contradict these findings. In that study, elderly subjects (6078 years) performed 12 weeks of resistance training with simultaneous daily ibuprofen treatment of 1200 mg. The increase in muscle size was substantially greater with ibuprofen compared with placebo,15 and this was supported by acute data showing no interference of ibuprofen on muscle protein synthesis in the same age group.31 Thus, interestingly, there may be distinct differences in the response to resistance training and NSAID consumption in the young vs. the elderly, and probably also in the mechanistic underpinnings of exercise-induced tissue remodelling in these age groups. Specifically, in the present cohort of young subjects, it is possible that blunting of important inflammatory processes, as reflected by the downregulated IL-6 gene expression, contributed to the attenuated hypertrophic response because previous studies have shown that induction of IL-6, and also other inflammatory and proteolytic factors, has an important role in muscle regenerative processes during hypertrophic conditions.32,33 In contrast, the role of inflammatory processes may be different in the elderly where an ibuprofen-induced downregulation of IL-6 could reduce chronic low-grade inflammation and thereby restore the blunted anabolic response to resistance exercise typically seen in aged populations.34 Thus, based on the current data and given the complex regulation of mRNA and protein levels,35,36 future studies should directly compare the response to resistance exercise and NSAID treatment in young vs. old populations as well as incorporate better time resolution, including both acute and chronic biopsy time points and perhaps also higher-throughput techniques, to provide more conclusive evidence of the critical mechanisms regulating the interactive effects of NSAIDs and resistance exercise on muscle adaptations. The functional data showed that increases in muscle strength were attenuated in IBU compared with ASA, but only in the FW leg. In our mind, this leads to two questions: first, if this strength difference was explained by the larger increase in muscle size in the control group, why was strength not reduced in the WS leg? Second, if not muscle size, what other mechanisms could explain the fact that strength was negatively affected by ibuprofen only in the FW leg? Regarding the first question, although muscle mass and strength are generally highly correlated at baseline in pre-training situations,37,38 the same does not necessarily apply when it comes to increases in strength and muscle size following short-term resistance training.39,40 This was also the case in the current study, where in fact the correlation between changes in muscle size and strength was very weak (R2 ~0.05; data not shown). Thus, it appears that strength gains can occur irrespective of the magnitude of increase in muscle volume and hence, this could explain why, in the WS leg, the larger increase in muscle volume for the ASA group did not result in a larger increase in strength compared with IBU. It is plausible that with longer-term training, once neural adaptations have plateaued,41 the relationship between muscle size and strength would be restored and hence the negative effect of ibuprofen on strength would be even more evident. As to the second question raised above, we did speculate beforehand that perhaps NSAID consumption could affect acute training performance and thereby the capacity to perform high-intensity repetitive work bouts. It appeared at first that the strength reduction in the FW leg was not related to a reduction in day-to-day training performance, as both groups performed an equal amount of work throughout the 8-week training programme. Interestingly, however, a closer look at the data in Figure 1 reveals that the ibuprofen group certainly showed a levelling-off effect during the last week of flywheel training, which likely explains the lower strength gains noted. Regarding the logical follow-up question of why training performance in the FW leg was negatively affected by ibuprofen only at the end of the training period, we are unable to provide a definite answer. However, given that the main differences between the two training modes is the eccentric overload, provoking greater inflammatory stimulus, and the maximal unlimited resistance provided by the flywheel device,21,42 it is tempting to speculate that one (or both) of these two features are particularly prone to ibuprofen treatment, at least after a few weeks of accumulated training. It should also be noted that day-to-day performance levels varied much more in the FW leg, indicating that this training regime was more stressful for the subjects. Alternatively, as indicated earlier, the relationship between muscle mass and strength became more important at the end of the training period, and hence, the levelling-off phenomenon in the IBU group was due to the compromised hypertrophic development. Altogether, based on the current data and given the knowledge of different time resolutions for the underlying mechanisms of muscle strength, longer training studies could clarify whether interference in muscle growth will be associated with reduced muscle strength, and whether different training modes, such as eccentric overload, are even more sensitive to concomitant NSAID treatment. Notwithstanding, our findings raise the concern that resistance-training studies employing strict work-matched increases across groups might overlook important effects of various factors such as medical treatments or supplements that would have become evident if maximal efforts had been allowed throughout each set and training session. In summary, we show for the first time that maximal over-the-counter doses of NSAIDs compromise resistance exercise-induced increases in muscle size and strength in young adults. The gains in muscle size were attenuated by ibuprofen independent of the type of training performed, whereas muscle strength was attenuated only when training was performed with maximal all-out repetitions. Furthermore, while the resistance-training intervention resulted in several muscle molecular adaptations, the only marked difference across medical treatment was a significant ibuprofen-induced reduction in IL-6 gene expression, which in our mind reflected a changed inflammatory environment that, speculatively, contributed to the attenuated hypertrophic development in the ibuprofen group. This study improves our understanding of how NSAIDs work and interacts with chronic exercise responses, and considering the potency of the drug to modify muscle mass and function, the mechanistic findings should contribute to a better understanding of regulation of muscle growth in general. More importantly, however, the results have implications for the millions of individuals worldwide who consume NSAIDs on a regular basis while trying to obtain the best possible benefits of resistance training.', 'content_type': 'text', 'score': None, 'meta': {}, 'id_hash_keys': ['content'], 'embedding': '<embedding of shape (768,)>', 'id': '60b653a8599c46ea25daf045f69f22e9'}>],\n",
       " 'root_node': 'File',\n",
       " 'params': {},\n",
       " 'file_paths': ['../data/testing_2023-11-23//journal_article.txt'],\n",
       " 'node_id': 'Retriever'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "p = Pipeline()\n",
    "p.add_node(component=text_converter, name=\"TextConverter\", inputs=[\"File\"])\n",
    "p.add_node(component=preprocessor, name=\"PreProcessor\", inputs=[\"TextConverter\"])\n",
    "p.add_node(component=document_store, name=\"DocumentStore\", inputs=[\"PreProcessor\"])\n",
    "p.add_node(component=retriever, name=\"Retriever\", inputs=[\"DocumentStore\"])\n",
    "\n",
    "\n",
    "p.run(file_paths=[f\"{path}/journal_article.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update embeddings before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating Embedding:   0%|          | 0/1 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b57fdaec9e440bbaaf44ca56d1cb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:01, 8612.66 docs/s]      \n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever)\n",
    "document_store.save(index_path=f'{path}/{index_filename}', config_path=f'{path}/{config_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import TextConverter\n",
    "from haystack.nodes import PreProcessor\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.nodes import TransformersSummarizer\n",
    "from transformers import GenerationConfig\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
    "from haystack.nodes import EmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_node_dict = dict()\n",
    "output_dict = dict()\n",
    "system_message_dict = dict()\n",
    "prompt_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    " 'sshleifer/distilbart-cnn-12-6',\n",
    " 'facebook/bart-large-cnn', \n",
    " 'philschmid/bart-large-cnn-samsum',\n",
    " 'philschmid/flan-t5-base-samsum'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'haystack.document_stores.faiss.FAISSDocumentStore'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Document: {'content': 'High doses of anti-inflammatory drugs compromise muscle strength and hypertrophic adaptations to resistance training in young adults.\\n\\nDiscussion\\nThe interest in this study was spurred by the intriguing observation that while NSAIDs might have a negative impact on acute exercise responses (satellite cell activity, translational signalling and protein synthesis), previous human studies have failed to demonstrate a detrimental effect of NSAIDs on the development of muscle hypertrophy in response to chronic resistance training in young adults, possibly due to differences in drug dosage across studies. Accordingly, in the current study, healthy young men and women performed 8 weeks of supervised resistance training with concomitant high- or low-dose NSAID treatment. The major and novel findings were that 1) maximal overthe-counter doses of ibuprofen compromised resistance exercise-induced muscle hypertropy\\nindependent of training mode; 2) increases in muscle strength were attenuated by ibuprofen only when training was performed with maximal all-out repetitions; 3) while the resistance-training intervention resulted in several muscle molecular adaptations, the only marked difference across medical treatment was a significant ibuprofen-induced downregulation of the inflammatory cytokine IL-6 mRNA, compared with an upregulation in the ASA group. This is the first study showing that daily consumption of high doses of NSAIDs attenuates strength and muscle hypertrophic adaptations to resistance training in young healthy individuals. We acknowledge that a limitation of the current study was that we did not include a non-treated control group. However, the increase in muscle volume (7.5%) in the ASA group was of a similar, and expected, magnitude to that previously reported by our group20 and others.21,22 In the light of this, the magnitude of the reduction in muscle hypertrophy in response to the ibuprofen treatment was quite remarkable and, if anything, should the ASA treatment have had a small effect on the adaptive response, it would only have masked an even greater difference across groups than what is reported herein. Nonetheless, given the marked effect of ibuprofen and the fact that the increase in muscle size in the control group (0.14% per day) was of similar magnitude as the average rate of hypertrophy reported in past studies employing knee-extensor resistance training,23 we are confident that our data provide strong proof-of-principle evidence that the effect of NSAIDs on muscle adaptations to resistance exercise is dependent of the dose of intake. The rationale for using acetylsalicylic acid instead of ibuprofen as a low-dose comparator in the current study was based on the fact that when the drug is consumed orally, it undergoes substantial presystemic hydrolysis in the gut and liver before it enters the systemic bloodstream. As the drug will, however, encounter blood in the portal circulation, low doses of acetylsalicylic acid will exert its antiplatelet effect with no or limited effect on systemic targets such as peripheral tissue.1618 Consequently, the potential circulatory effects are factored out and we hypothesize that the negative effect of ibuprofen was due to muscle-specific COX inhibition rather than the antiplatelet effect achieved by both ibuprofen and low doses of acetylsalicylic acid.18,24 The results of the present study are in agreement with animal studies showing an inhibitory effect of COX inhibitors on muscle hypertrophy.8,9,25 They also agree with acute human data reporting attenuated protein synthesis,5 translational signalling13 and satellite cell activity11,12 in response to resistance training with concomitant high-dose NSAID administration. Our hypothesis of a dose-dependent effect is also supported by the only comparable training study in young healthy subjects.14 That particular study reported no effect of ibuprofen on muscle hypertrophy or strength gains after 6 weeks of training consisting of six sets of biceps curls 23 days week---------------1 . The drug dose was consumed on training days only, resulting in a total intake of 8001200 mg week---------------1 , 14 compared with 1200 mg per day in the current study. This indeed highlights the potential importance of drug dosage where, evidently, intake of maximal over-the-counter doses is potent enough to interfere with the normal hypertrophic development of 0.10.2% per day seen in the ASA group as well as in other studies employing conventional resistance-training programmes for the knee extensors.23 It is generally agreed that repeated increases in muscle protein synthesis following each exercise bout is the most important mechanism underlying training-induced muscle hypertrophy.26,27 Thus, it seems plausible to suggest that the main explanation for the clear attenuation of hypertrophy, which was evident in both training modes (FW and WS), was diminished prostaglandin production and hence decreased muscle protein synthetic response after each training session in the IBU group. Indeed, there is increasing evidence that COX and prostaglandins play an important role in regulating the molecular events controlling muscle hypertrophy. For example, C2C12 myotube diameter was shown to be regulated by PGF2a in an mTORdependent manner7 , and exercise-induced increases in p70S6K (downstream of mTOR) was blunted by ibuprofen treatment in the early hours following acute resistance exercise.13 In the current study, however, there were no group interactions for any of the target proteins examined, suggesting that the ibuprofenmodulating effect on muscle adaptations is not associated with differential expression of steady-state proteins in response to chronic training. Perhaps assessing satellite cell content,11 or the phosphorylation levels of translational signalling proteins in response to acute exercise,13 would have provided more mechanistic insights. We measured several key molecular markers for COX and prostaglandin-mediated metabolism, regulators of muscle growth and atrophy, and several cytokines and myokines that have been shown to regulate skeletal muscle protein metabolism and exercise adaptations.4 The most clear-cut molecular evidence for an effect of ibuprofen on peripheral muscle tissue was the marked drug effect on IL-6 mRNA, where levels in the ibuprofen group were downregulated despite a significant upregulation in the control group. The reduction of IL-6 in the ibuprofen group is coherent with previous studies suggesting PGE2 as a stimulator of IL-6 transcription in both human muscle28 and other cell types.29 It has previously been reported that the NSAID-modulating effects on muscle hypertrophy in older subjects were associated with lowered expression of IL-6 and subsequently MuRF-1, resulting in a more beneficial cellular environment for muscle growth.30 While our data are coherent with that of Trappe and colleagues regarding the expression of IL-6 in the ibuprofen-treated group (downregulated) compared to the control group (upregulated), the muscle hypertrophy data certainly contradict these findings. In that study, elderly subjects (6078 years) performed 12 weeks of resistance training with simultaneous daily ibuprofen treatment of 1200 mg. The increase in muscle size was substantially greater with ibuprofen compared with placebo,15 and this was supported by acute data showing no interference of ibuprofen on muscle protein synthesis in the same age group.31 Thus, interestingly, there may be distinct differences in the response to resistance training and NSAID consumption in the young vs. the elderly, and probably also in the mechanistic underpinnings of exercise-induced tissue remodelling in these age groups. Specifically, in the present cohort of young subjects, it is possible that blunting of important inflammatory processes, as reflected by the downregulated IL-6 gene expression, contributed to the attenuated hypertrophic response because previous studies have shown that induction of IL-6, and also other inflammatory and proteolytic factors, has an important role in muscle regenerative processes during hypertrophic conditions.32,33 In contrast, the role of inflammatory processes may be different in the elderly where an ibuprofen-induced downregulation of IL-6 could reduce chronic low-grade inflammation and thereby restore the blunted anabolic response to resistance exercise typically seen in aged populations.34 Thus, based on the current data and given the complex regulation of mRNA and protein levels,35,36 future studies should directly compare the response to resistance exercise and NSAID treatment in young vs. old populations as well as incorporate better time resolution, including both acute and chronic biopsy time points and perhaps also higher-throughput techniques, to provide more conclusive evidence of the critical mechanisms regulating the interactive effects of NSAIDs and resistance exercise on muscle adaptations. The functional data showed that increases in muscle strength were attenuated in IBU compared with ASA, but only in the FW leg. In our mind, this leads to two questions: first, if this strength difference was explained by the larger increase in muscle size in the control group, why was strength not reduced in the WS leg? Second, if not muscle size, what other mechanisms could explain the fact that strength was negatively affected by ibuprofen only in the FW leg? Regarding the first question, although muscle mass and strength are generally highly correlated at baseline in pre-training situations,37,38 the same does not necessarily apply when it comes to increases in strength and muscle size following short-term resistance training.39,40 This was also the case in the current study, where in fact the correlation between changes in muscle size and strength was very weak (R2 ~0.05; data not shown). Thus, it appears that strength gains can occur irrespective of the magnitude of increase in muscle volume and hence, this could explain why, in the WS leg, the larger increase in muscle volume for the ASA group did not result in a larger increase in strength compared with IBU. It is plausible that with longer-term training, once neural adaptations have plateaued,41 the relationship between muscle size and strength would be restored and hence the negative effect of ibuprofen on strength would be even more evident. As to the second question raised above, we did speculate beforehand that perhaps NSAID consumption could affect acute training performance and thereby the capacity to perform high-intensity repetitive work bouts. It appeared at first that the strength reduction in the FW leg was not related to a reduction in day-to-day training performance, as both groups performed an equal amount of work throughout the 8-week training programme. Interestingly, however, a closer look at the data in Figure 1 reveals that the ibuprofen group certainly showed a levelling-off effect during the last week of flywheel training, which likely explains the lower strength gains noted. Regarding the logical follow-up question of why training performance in the FW leg was negatively affected by ibuprofen only at the end of the training period, we are unable to provide a definite answer. However, given that the main differences between the two training modes is the eccentric overload, provoking greater inflammatory stimulus, and the maximal unlimited resistance provided by the flywheel device,21,42 it is tempting to speculate that one (or both) of these two features are particularly prone to ibuprofen treatment, at least after a few weeks of accumulated training. It should also be noted that day-to-day performance levels varied much more in the FW leg, indicating that this training regime was more stressful for the subjects. Alternatively, as indicated earlier, the relationship between muscle mass and strength became more important at the end of the training period, and hence, the levelling-off phenomenon in the IBU group was due to the compromised hypertrophic development. Altogether, based on the current data and given the knowledge of different time resolutions for the underlying mechanisms of muscle strength, longer training studies could clarify whether interference in muscle growth will be associated with reduced muscle strength, and whether different training modes, such as eccentric overload, are even more sensitive to concomitant NSAID treatment. Notwithstanding, our findings raise the concern that resistance-training studies employing strict work-matched increases across groups might overlook important effects of various factors such as medical treatments or supplements that would have become evident if maximal efforts had been allowed throughout each set and training session. In summary, we show for the first time that maximal over-the-counter doses of NSAIDs compromise resistance exercise-induced increases in muscle size and strength in young adults. The gains in muscle size were attenuated by ibuprofen independent of the type of training performed, whereas muscle strength was attenuated only when training was performed with maximal all-out repetitions. Furthermore, while the resistance-training intervention resulted in several muscle molecular adaptations, the only marked difference across medical treatment was a significant ibuprofen-induced reduction in IL-6 gene expression, which in our mind reflected a changed inflammatory environment that, speculatively, contributed to the attenuated hypertrophic development in the ibuprofen group. This study improves our understanding of how NSAIDs work and interacts with chronic exercise responses, and considering the potency of the drug to modify muscle mass and function, the mechanistic findings should contribute to a better understanding of regulation of muscle growth in general. More importantly, however, the results have implications for the millions of individuals worldwide who consume NSAIDs on a regular basis while trying to obtain the best possible benefits of resistance training.', 'content_type': 'text', 'score': None, 'meta': {'vector_id': '0'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '60b653a8599c46ea25daf045f69f22e9'}>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_timestamp = '_2023-11-23_1341'\n",
    "index_filename = 'journal_article_index'+file_timestamp\n",
    "config_filename = 'journal_article_config'+file_timestamp\n",
    "faiss_filename = 'faiss_document_store'+file_timestamp\n",
    "# path = '../data/testing_2023-11-23/'\n",
    "path = path\n",
    "saved_document_store = FAISSDocumentStore.load(\n",
    "    index_path=f'{path}/{index_filename}', config_path=f'{path}/{config_filename}'\n",
    "    )\n",
    "print(type(saved_document_store))\n",
    "saved_document_store.get_all_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_document_store.get_all_documents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 1 `sshleifer/distilbart-cnn-12-6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model sshleifer/distilbart-cnn-12-6 is not supported - no matching invocation layer found. Currently supported invocation layers are: [<class 'haystack.nodes.prompt.invocation_layer.open_ai.OpenAIInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.azure_open_ai.AzureOpenAIInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.chatgpt.ChatGPTInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.azure_chatgpt.AzureChatGPTInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.anthropic_claude.AnthropicClaudeInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.cohere.CohereInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.hugging_face.HFLocalInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.hugging_face_inference.HFInferenceEndpointInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_base.SageMakerBaseInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_meta.SageMakerMetaInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_hf_infer.SageMakerHFInferenceInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_hf_text_gen.SageMakerHFTextGenerationInvocationLayer'>] You can implement and provide custom invocation layer for sshleifer/distilbart-cnn-12-6 by subclassing PromptModelInvocationLayer. Also please ensure you are authorised to load the model sshleifer/distilbart-cnn-12-6 and you are logged-in into the huggingface cli.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia 2023-11-23 explore models.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m prompt \u001b[39m=\u001b[39m PromptTemplate( \u001b[39m# https://docs.haystack.deepset.ai/docs/prompt_node#prompttemplates\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     prompt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{query}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m Messages: \u001b[39m\u001b[39m{\u001b[39m\u001b[39mjoin(documents)} \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mSummary: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m prompt_dict[iteration] \u001b[39m=\u001b[39m prompt\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m prompt_node \u001b[39m=\u001b[39m PromptNode( \u001b[39m# https://docs.haystack.deepset.ai/reference/prompt-node-api # https://docs.haystack.deepset.ai/docs/prompt_node#in-a-pipeline\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     model_name, api_key\u001b[39m=\u001b[39;49mhf_access_token, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length, \u001b[39m# The maximum number of tokens the generated text output can have,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     default_prompt_template\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m prompt_node_dict[iteration] \u001b[39m=\u001b[39m prompt_node\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m system_message_dict[iteration] \u001b[39m=\u001b[39m system_message\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:46\u001b[0m, in \u001b[0;36mexportable_to_yaml.<locals>.wrapper_exportable_to_yaml\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_component_config[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m][k] \u001b[39m=\u001b[39m v\n\u001b[1;32m     45\u001b[0m \u001b[39m# Call the actual __init__ function with all the arguments\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m init_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:112\u001b[0m, in \u001b[0;36mPromptNode.__init__\u001b[0;34m(self, model_name_or_path, default_prompt_template, output_variable, max_length, api_key, use_auth_token, use_gpu, devices, stop_words, top_k, debug, model_kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m=\u001b[39m debug\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model_name_or_path, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt_model \u001b[39m=\u001b[39m PromptModel(\n\u001b[1;32m    113\u001b[0m         model_name_or_path\u001b[39m=\u001b[39;49mmodel_name_or_path,\n\u001b[1;32m    114\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m    115\u001b[0m         api_key\u001b[39m=\u001b[39;49mapi_key,\n\u001b[1;32m    116\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    117\u001b[0m         use_gpu\u001b[39m=\u001b[39;49muse_gpu,\n\u001b[1;32m    118\u001b[0m         devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    119\u001b[0m         model_kwargs\u001b[39m=\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(model_name_or_path, PromptModel):\n\u001b[1;32m    122\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt_model \u001b[39m=\u001b[39m model_name_or_path\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:46\u001b[0m, in \u001b[0;36mexportable_to_yaml.<locals>.wrapper_exportable_to_yaml\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_component_config[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m][k] \u001b[39m=\u001b[39m v\n\u001b[1;32m     45\u001b[0m \u001b[39m# Call the actual __init__ function with all the arguments\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m init_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_model.py:71\u001b[0m, in \u001b[0;36mPromptModel.__init__\u001b[0;34m(self, model_name_or_path, max_length, api_key, use_auth_token, use_gpu, devices, invocation_layer_class, model_kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevices \u001b[39m=\u001b[39m devices\n\u001b[1;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_kwargs \u001b[39m=\u001b[39m model_kwargs \u001b[39mif\u001b[39;00m model_kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m---> 71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_invocation_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_invocation_layer(invocation_layer_class\u001b[39m=\u001b[39;49minvocation_layer_class)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_model.py:96\u001b[0m, in \u001b[0;36mPromptModel.create_invocation_layer\u001b[0;34m(self, invocation_layer_class)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m invocation_layer\u001b[39m.\u001b[39msupports(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_kwargs):\n\u001b[1;32m     93\u001b[0m         \u001b[39mreturn\u001b[39;00m invocation_layer(\n\u001b[1;32m     94\u001b[0m             model_name_or_path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path, max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_kwargs\n\u001b[1;32m     95\u001b[0m         )\n\u001b[0;32m---> 96\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not supported - no matching invocation layer found.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Currently supported invocation layers are: \u001b[39m\u001b[39m{\u001b[39;00mPromptModelInvocationLayer\u001b[39m.\u001b[39minvocation_layer_providers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m You can implement and provide custom invocation layer for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m by subclassing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPromptModelInvocationLayer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Also please ensure you are authorised to load the model \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m and you are \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlogged-in into the huggingface cli.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Model sshleifer/distilbart-cnn-12-6 is not supported - no matching invocation layer found. Currently supported invocation layers are: [<class 'haystack.nodes.prompt.invocation_layer.open_ai.OpenAIInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.azure_open_ai.AzureOpenAIInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.chatgpt.ChatGPTInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.azure_chatgpt.AzureChatGPTInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.anthropic_claude.AnthropicClaudeInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.cohere.CohereInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.hugging_face.HFLocalInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.hugging_face_inference.HFInferenceEndpointInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_base.SageMakerBaseInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_meta.SageMakerMetaInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_hf_infer.SageMakerHFInferenceInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_hf_text_gen.SageMakerHFTextGenerationInvocationLayer'>] You can implement and provide custom invocation layer for sshleifer/distilbart-cnn-12-6 by subclassing PromptModelInvocationLayer. Also please ensure you are authorised to load the model sshleifer/distilbart-cnn-12-6 and you are logged-in into the huggingface cli."
     ]
    }
   ],
   "source": [
    "iteration = iteration\n",
    "model_name = models_list[iteration - 1]\n",
    "max_length = 3000\n",
    "system_message = \"\"\"\n",
    "Summarize the messages to create a Frequently Asked Questions document.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate( # https://docs.haystack.deepset.ai/docs/prompt_node#prompttemplates\n",
    "    prompt='{query}\\n\\n Messages: {join(documents)} \\n\\nSummary: '\n",
    ")\n",
    "prompt_dict[iteration] = prompt\n",
    "\n",
    "prompt_node = PromptNode( # https://docs.haystack.deepset.ai/reference/prompt-node-api # https://docs.haystack.deepset.ai/docs/prompt_node#in-a-pipeline\n",
    "    model_name, api_key=hf_access_token, \n",
    "    max_length=max_length, # The maximum number of tokens the generated text output can have,\n",
    "    default_prompt_template=prompt,\n",
    "    )\n",
    "prompt_node_dict[iteration] = prompt_node\n",
    "system_message_dict[iteration] = system_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### facebook/bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model facebook/bart-large-cnn is not supported - no matching invocation layer found. Currently supported invocation layers are: [<class 'haystack.nodes.prompt.invocation_layer.open_ai.OpenAIInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.azure_open_ai.AzureOpenAIInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.chatgpt.ChatGPTInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.azure_chatgpt.AzureChatGPTInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.anthropic_claude.AnthropicClaudeInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.cohere.CohereInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.hugging_face.HFLocalInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.hugging_face_inference.HFInferenceEndpointInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_base.SageMakerBaseInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_meta.SageMakerMetaInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_hf_infer.SageMakerHFInferenceInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_hf_text_gen.SageMakerHFTextGenerationInvocationLayer'>] You can implement and provide custom invocation layer for facebook/bart-large-cnn by subclassing PromptModelInvocationLayer. Also please ensure you are authorised to load the model facebook/bart-large-cnn and you are logged-in into the huggingface cli.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia 2023-11-23 explore models.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m prompt \u001b[39m=\u001b[39m PromptTemplate( \u001b[39m# https://docs.haystack.deepset.ai/docs/prompt_node#prompttemplates\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     prompt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{query}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m Messages: \u001b[39m\u001b[39m{\u001b[39m\u001b[39mjoin(documents)} \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mSummary: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m prompt_dict[iteration] \u001b[39m=\u001b[39m prompt\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m prompt_node \u001b[39m=\u001b[39m PromptNode( \u001b[39m# https://docs.haystack.deepset.ai/reference/prompt-node-api # https://docs.haystack.deepset.ai/docs/prompt_node#in-a-pipeline\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     model_name, api_key\u001b[39m=\u001b[39;49mhf_access_token, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length, \u001b[39m# The maximum number of tokens the generated text output can have,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     default_prompt_template\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m prompt_node_dict[iteration] \u001b[39m=\u001b[39m prompt_node\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m system_message_dict[iteration] \u001b[39m=\u001b[39m system_message\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:46\u001b[0m, in \u001b[0;36mexportable_to_yaml.<locals>.wrapper_exportable_to_yaml\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_component_config[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m][k] \u001b[39m=\u001b[39m v\n\u001b[1;32m     45\u001b[0m \u001b[39m# Call the actual __init__ function with all the arguments\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m init_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:112\u001b[0m, in \u001b[0;36mPromptNode.__init__\u001b[0;34m(self, model_name_or_path, default_prompt_template, output_variable, max_length, api_key, use_auth_token, use_gpu, devices, stop_words, top_k, debug, model_kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m=\u001b[39m debug\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model_name_or_path, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt_model \u001b[39m=\u001b[39m PromptModel(\n\u001b[1;32m    113\u001b[0m         model_name_or_path\u001b[39m=\u001b[39;49mmodel_name_or_path,\n\u001b[1;32m    114\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m    115\u001b[0m         api_key\u001b[39m=\u001b[39;49mapi_key,\n\u001b[1;32m    116\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    117\u001b[0m         use_gpu\u001b[39m=\u001b[39;49muse_gpu,\n\u001b[1;32m    118\u001b[0m         devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    119\u001b[0m         model_kwargs\u001b[39m=\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(model_name_or_path, PromptModel):\n\u001b[1;32m    122\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt_model \u001b[39m=\u001b[39m model_name_or_path\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:46\u001b[0m, in \u001b[0;36mexportable_to_yaml.<locals>.wrapper_exportable_to_yaml\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_component_config[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m][k] \u001b[39m=\u001b[39m v\n\u001b[1;32m     45\u001b[0m \u001b[39m# Call the actual __init__ function with all the arguments\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m init_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_model.py:71\u001b[0m, in \u001b[0;36mPromptModel.__init__\u001b[0;34m(self, model_name_or_path, max_length, api_key, use_auth_token, use_gpu, devices, invocation_layer_class, model_kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevices \u001b[39m=\u001b[39m devices\n\u001b[1;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_kwargs \u001b[39m=\u001b[39m model_kwargs \u001b[39mif\u001b[39;00m model_kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m---> 71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_invocation_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_invocation_layer(invocation_layer_class\u001b[39m=\u001b[39;49minvocation_layer_class)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_model.py:96\u001b[0m, in \u001b[0;36mPromptModel.create_invocation_layer\u001b[0;34m(self, invocation_layer_class)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m invocation_layer\u001b[39m.\u001b[39msupports(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_kwargs):\n\u001b[1;32m     93\u001b[0m         \u001b[39mreturn\u001b[39;00m invocation_layer(\n\u001b[1;32m     94\u001b[0m             model_name_or_path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path, max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_kwargs\n\u001b[1;32m     95\u001b[0m         )\n\u001b[0;32m---> 96\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not supported - no matching invocation layer found.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Currently supported invocation layers are: \u001b[39m\u001b[39m{\u001b[39;00mPromptModelInvocationLayer\u001b[39m.\u001b[39minvocation_layer_providers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m You can implement and provide custom invocation layer for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m by subclassing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPromptModelInvocationLayer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Also please ensure you are authorised to load the model \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m and you are \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlogged-in into the huggingface cli.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Model facebook/bart-large-cnn is not supported - no matching invocation layer found. Currently supported invocation layers are: [<class 'haystack.nodes.prompt.invocation_layer.open_ai.OpenAIInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.azure_open_ai.AzureOpenAIInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.chatgpt.ChatGPTInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.azure_chatgpt.AzureChatGPTInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.anthropic_claude.AnthropicClaudeInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.cohere.CohereInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.hugging_face.HFLocalInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.hugging_face_inference.HFInferenceEndpointInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_base.SageMakerBaseInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_meta.SageMakerMetaInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_hf_infer.SageMakerHFInferenceInvocationLayer'>, <class 'haystack.nodes.prompt.invocation_layer.sagemaker_hf_text_gen.SageMakerHFTextGenerationInvocationLayer'>] You can implement and provide custom invocation layer for facebook/bart-large-cnn by subclassing PromptModelInvocationLayer. Also please ensure you are authorised to load the model facebook/bart-large-cnn and you are logged-in into the huggingface cli."
     ]
    }
   ],
   "source": [
    "iteration = iteration\n",
    "model_name = models_list[iteration]\n",
    "max_length = 3000\n",
    "system_message = \"\"\"\n",
    "Summarize the messages to create a Frequently Asked Questions document.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate( # https://docs.haystack.deepset.ai/docs/prompt_node#prompttemplates\n",
    "    prompt='{query}\\n\\n Messages: {join(documents)} \\n\\nSummary: '\n",
    ")\n",
    "prompt_dict[iteration] = prompt\n",
    "\n",
    "prompt_node = PromptNode( # https://docs.haystack.deepset.ai/reference/prompt-node-api # https://docs.haystack.deepset.ai/docs/prompt_node#in-a-pipeline\n",
    "    model_name, api_key=hf_access_token, \n",
    "    max_length=max_length, # The maximum number of tokens the generated text output can have,\n",
    "    default_prompt_template=prompt,\n",
    "    )\n",
    "prompt_node_dict[iteration] = prompt_node\n",
    "system_message_dict[iteration] = system_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google/flan-t5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51db97e56eb7465bb75a88dd5adbf415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34135ee665254d5192ffbc8792bbe4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f678b1c639c34b948bc0f5b095c8aff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e650824c8fd4171a2196a5ff2ee8d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration = iteration\n",
    "model_name = models_list[iteration]\n",
    "max_length = 3000\n",
    "system_message = \"\"\"\n",
    "Summarize the messages to create a Frequently Asked Questions document.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate( # https://docs.haystack.deepset.ai/docs/prompt_node#prompttemplates\n",
    "    prompt='{query}\\n\\n Messages: {join(documents)} \\n\\nSummary: '\n",
    ")\n",
    "prompt_dict[iteration] = prompt\n",
    "\n",
    "prompt_node = PromptNode( # https://docs.haystack.deepset.ai/reference/prompt-node-api # https://docs.haystack.deepset.ai/docs/prompt_node#in-a-pipeline\n",
    "    # model_name, # Default is \"google/flan-t5-base\"\n",
    "    api_key=hf_access_token, \n",
    "    max_length=max_length, # The maximum number of tokens the generated text output can have,\n",
    "    default_prompt_template=prompt,\n",
    "    )\n",
    "prompt_node_dict[iteration] = prompt_node\n",
    "system_message_dict[iteration] = system_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The prompt has been truncated from 3053 tokens to 0 tokens so that the prompt length and answer length (3000 tokens) fit within the max token limit (1024 tokens). Shorten the prompt to prevent it from being cut off.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Exception while running node 'PromptNode': HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":[\"Error in `parameters.max_new_tokens`: ensure this value is less than or equal to 250\"]}\nEnable debug logging to see the data that was passed when the pipeline failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:237\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer._post\u001b[0;34m(self, data, stream, attempts, status_codes_to_retry, timeout)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     response \u001b[39m=\u001b[39m request_with_retry(\n\u001b[1;32m    238\u001b[0m         method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    239\u001b[0m         status_codes_to_retry\u001b[39m=\u001b[39;49mstatus_codes_to_retry,\n\u001b[1;32m    240\u001b[0m         attempts\u001b[39m=\u001b[39;49mattempts,\n\u001b[1;32m    241\u001b[0m         url\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl,\n\u001b[1;32m    242\u001b[0m         headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    243\u001b[0m         json\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    244\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    245\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    247\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/utils/requests_utils.py:93\u001b[0m, in \u001b[0;36mrequest_with_retry\u001b[0;34m(attempts, status_codes_to_retry, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m# We raise here too in case the request failed with a status code that\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m# won't trigger a retry, this way the call will still cause an explicit exception\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m res\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-base",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHuggingFaceInferenceError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:567\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    566\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 567\u001b[0m node_output, stream_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_node(node_id, node_input)\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_debug\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m node_output \u001b[39mand\u001b[39;00m node_id \u001b[39min\u001b[39;00m node_output[\u001b[39m\"\u001b[39m\u001b[39m_debug\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:469\u001b[0m, in \u001b[0;36mPipeline._run_node\u001b[0;34m(self, node_id, node_input)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_node\u001b[39m(\u001b[39mself\u001b[39m, node_id: \u001b[39mstr\u001b[39m, node_input: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Dict, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph\u001b[39m.\u001b[39;49mnodes[node_id][\u001b[39m\"\u001b[39;49m\u001b[39mcomponent\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49m_dispatch_run(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnode_input)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:201\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mThe Pipelines call this method when run() is executed. This method in turn executes the _dispatch_run_general()\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39mmethod with the correct run method.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_run_general(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:245\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run_general\u001b[0;34m(self, run_method, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         run_inputs[key] \u001b[39m=\u001b[39m value\n\u001b[0;32m--> 245\u001b[0m output, stream \u001b[39m=\u001b[39m run_method(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_params)\n\u001b[1;32m    247\u001b[0m \u001b[39m# Collect debug information\u001b[39;00m\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:310\u001b[0m, in \u001b[0;36mPromptNode.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, invocation_context, prompt_template, generation_kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m invocation_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare(\n\u001b[1;32m    307\u001b[0m     query, file_paths, labels, documents, meta, invocation_context, prompt_template, generation_kwargs\n\u001b[1;32m    308\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minvocation_context, prompt_collector\u001b[39m=\u001b[39;49mprompt_collector)\n\u001b[1;32m    312\u001b[0m prompt_template_resolved: PromptTemplate \u001b[39m=\u001b[39m invocation_context\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:138\u001b[0m, in \u001b[0;36mPromptNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt(prompt_template, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:167\u001b[0m, in \u001b[0;36mPromptNode.prompt\u001b[0;34m(self, prompt_template, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mPrompt being sent to LLM with prompt \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m and kwargs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, prompt, kwargs_copy)\n\u001b[0;32m--> 167\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt_model\u001b[39m.\u001b[39;49minvoke(prompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_copy)\n\u001b[1;32m    168\u001b[0m results\u001b[39m.\u001b[39mextend(output)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_model.py:113\u001b[0m, in \u001b[0;36mPromptModel.invoke\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mTakes in a prompt and returns a list of responses using the underlying invocation layer.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m:return: A list of model-generated responses for the prompt or prompts.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_invocation_layer\u001b[39m.\u001b[39;49minvoke(prompt\u001b[39m=\u001b[39;49mprompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:173\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer.invoke\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    157\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdetails\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdetails\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwatermark\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mwatermark\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m    172\u001b[0m }\n\u001b[0;32m--> 173\u001b[0m response: requests\u001b[39m.\u001b[39mResponse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    174\u001b[0m     data\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt, \u001b[39m\"\u001b[39;49m\u001b[39mparameters\u001b[39;49m\u001b[39m\"\u001b[39;49m: params, \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream}, stream\u001b[39m=\u001b[39;49mstream\n\u001b[1;32m    175\u001b[0m )\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:254\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer._post\u001b[0;34m(self, data, stream, attempts, status_codes_to_retry, timeout)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[39mraise\u001b[39;00m HuggingFaceInferenceUnauthorizedError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI key is invalid: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mraise\u001b[39;00m HuggingFaceInferenceError(\n\u001b[1;32m    255\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHuggingFace Inference returned an error.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStatus code: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mResponse body: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         status_code\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mstatus_code,  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mHuggingFaceInferenceError\u001b[0m: HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":[\"Error in `parameters.max_new_tokens`: ensure this value is less than or equal to 250\"]}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia 2023-11-23 explore models.ipynb Cell 24\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m summarize_pipeline \u001b[39m=\u001b[39m Pipeline()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m summarize_pipeline\u001b[39m.\u001b[39madd_node(component\u001b[39m=\u001b[39mprompt_node, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPromptNode\u001b[39m\u001b[39m\"\u001b[39m, inputs\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mQuery\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m output \u001b[39m=\u001b[39m summarize_pipeline\u001b[39m.\u001b[39;49mrun(query\u001b[39m=\u001b[39;49msystem_message, documents\u001b[39m=\u001b[39;49msaved_document_store\u001b[39m.\u001b[39;49mget_all_documents())\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m output_dict[iteration] \u001b[39m=\u001b[39m output\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m output\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:574\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    571\u001b[0m     \u001b[39m# The input might be a really large object with thousands of embeddings.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[39m# If you really want to see it, raise the log level.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mException while running node \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with input \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, node_id, node_input)\n\u001b[0;32m--> 574\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException while running node \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnode_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mEnable debug logging to see the data that was passed when the pipeline failed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    577\u001b[0m queue\u001b[39m.\u001b[39mpop(node_id)\n\u001b[1;32m    578\u001b[0m \u001b[39m#\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Exception while running node 'PromptNode': HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":[\"Error in `parameters.max_new_tokens`: ensure this value is less than or equal to 250\"]}\nEnable debug logging to see the data that was passed when the pipeline failed."
     ]
    }
   ],
   "source": [
    "\n",
    "summarize_pipeline = Pipeline()\n",
    "\n",
    "summarize_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Query\"])\n",
    "\n",
    "output = summarize_pipeline.run(query=system_message, documents=saved_document_store.get_all_documents())\n",
    "output_dict[iteration] = output\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### philschmid/flan-t5-base-samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sshleifer/distilbart-cnn-12-6',\n",
       " 'facebook/bart-large-cnn',\n",
       " 'philschmid/bart-large-cnn-samsum',\n",
       " 'philschmid/flan-t5-base-samsum']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dbd31b23014073ad304b36e7ebffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fba346fad424381a77999ec6a6be093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa2fdc563b24db18ac8dcf261abcaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e887ee97eba3409ebda95ad0b556d9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration = iteration\n",
    "model_name = models_list[3]\n",
    "max_length = 3000\n",
    "system_message = \"\"\"\n",
    "Summarize the messages to create a Frequently Asked Questions document.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate( # https://docs.haystack.deepset.ai/docs/prompt_node#prompttemplates\n",
    "    prompt='{query}\\n\\n Messages: {join(documents)} \\n\\nSummary: '\n",
    ")\n",
    "prompt_dict[iteration] = prompt\n",
    "\n",
    "prompt_node = PromptNode( # https://docs.haystack.deepset.ai/reference/prompt-node-api # https://docs.haystack.deepset.ai/docs/prompt_node#in-a-pipeline\n",
    "    model_name, # Default is \"google/flan-t5-base\"\n",
    "    api_key=hf_access_token, \n",
    "    max_length=max_length, # The maximum number of tokens the generated text output can have,\n",
    "    default_prompt_template=prompt,\n",
    "    )\n",
    "prompt_node_dict[iteration] = prompt_node\n",
    "system_message_dict[iteration] = system_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "The prompt has been truncated from 3053 tokens to 0 tokens so that the prompt length and answer length (3000 tokens) fit within the max token limit (1024 tokens). Shorten the prompt to prevent it from being cut off.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Exception while running node 'PromptNode': HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":[\"Error in `parameters.max_new_tokens`: ensure this value is less than or equal to 250\"]}\nEnable debug logging to see the data that was passed when the pipeline failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:237\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer._post\u001b[0;34m(self, data, stream, attempts, status_codes_to_retry, timeout)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     response \u001b[39m=\u001b[39m request_with_retry(\n\u001b[1;32m    238\u001b[0m         method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    239\u001b[0m         status_codes_to_retry\u001b[39m=\u001b[39;49mstatus_codes_to_retry,\n\u001b[1;32m    240\u001b[0m         attempts\u001b[39m=\u001b[39;49mattempts,\n\u001b[1;32m    241\u001b[0m         url\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl,\n\u001b[1;32m    242\u001b[0m         headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    243\u001b[0m         json\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    244\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    245\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    247\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/utils/requests_utils.py:93\u001b[0m, in \u001b[0;36mrequest_with_retry\u001b[0;34m(attempts, status_codes_to_retry, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m# We raise here too in case the request failed with a status code that\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m# won't trigger a retry, this way the call will still cause an explicit exception\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m res\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/philschmid/flan-t5-base-samsum",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHuggingFaceInferenceError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:567\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    566\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 567\u001b[0m node_output, stream_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_node(node_id, node_input)\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_debug\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m node_output \u001b[39mand\u001b[39;00m node_id \u001b[39min\u001b[39;00m node_output[\u001b[39m\"\u001b[39m\u001b[39m_debug\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:469\u001b[0m, in \u001b[0;36mPipeline._run_node\u001b[0;34m(self, node_id, node_input)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_node\u001b[39m(\u001b[39mself\u001b[39m, node_id: \u001b[39mstr\u001b[39m, node_input: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Dict, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph\u001b[39m.\u001b[39;49mnodes[node_id][\u001b[39m\"\u001b[39;49m\u001b[39mcomponent\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49m_dispatch_run(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnode_input)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:201\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mThe Pipelines call this method when run() is executed. This method in turn executes the _dispatch_run_general()\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39mmethod with the correct run method.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_run_general(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:245\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run_general\u001b[0;34m(self, run_method, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         run_inputs[key] \u001b[39m=\u001b[39m value\n\u001b[0;32m--> 245\u001b[0m output, stream \u001b[39m=\u001b[39m run_method(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_params)\n\u001b[1;32m    247\u001b[0m \u001b[39m# Collect debug information\u001b[39;00m\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:310\u001b[0m, in \u001b[0;36mPromptNode.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, invocation_context, prompt_template, generation_kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m invocation_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare(\n\u001b[1;32m    307\u001b[0m     query, file_paths, labels, documents, meta, invocation_context, prompt_template, generation_kwargs\n\u001b[1;32m    308\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minvocation_context, prompt_collector\u001b[39m=\u001b[39;49mprompt_collector)\n\u001b[1;32m    312\u001b[0m prompt_template_resolved: PromptTemplate \u001b[39m=\u001b[39m invocation_context\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:138\u001b[0m, in \u001b[0;36mPromptNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt(prompt_template, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:167\u001b[0m, in \u001b[0;36mPromptNode.prompt\u001b[0;34m(self, prompt_template, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mPrompt being sent to LLM with prompt \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m and kwargs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, prompt, kwargs_copy)\n\u001b[0;32m--> 167\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt_model\u001b[39m.\u001b[39;49minvoke(prompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_copy)\n\u001b[1;32m    168\u001b[0m results\u001b[39m.\u001b[39mextend(output)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_model.py:113\u001b[0m, in \u001b[0;36mPromptModel.invoke\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mTakes in a prompt and returns a list of responses using the underlying invocation layer.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m:return: A list of model-generated responses for the prompt or prompts.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_invocation_layer\u001b[39m.\u001b[39;49minvoke(prompt\u001b[39m=\u001b[39;49mprompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:173\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer.invoke\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    157\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdetails\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdetails\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwatermark\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mwatermark\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m    172\u001b[0m }\n\u001b[0;32m--> 173\u001b[0m response: requests\u001b[39m.\u001b[39mResponse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    174\u001b[0m     data\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt, \u001b[39m\"\u001b[39;49m\u001b[39mparameters\u001b[39;49m\u001b[39m\"\u001b[39;49m: params, \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream}, stream\u001b[39m=\u001b[39;49mstream\n\u001b[1;32m    175\u001b[0m )\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:254\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer._post\u001b[0;34m(self, data, stream, attempts, status_codes_to_retry, timeout)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[39mraise\u001b[39;00m HuggingFaceInferenceUnauthorizedError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI key is invalid: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mraise\u001b[39;00m HuggingFaceInferenceError(\n\u001b[1;32m    255\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHuggingFace Inference returned an error.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStatus code: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mResponse body: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         status_code\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mstatus_code,  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mHuggingFaceInferenceError\u001b[0m: HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":[\"Error in `parameters.max_new_tokens`: ensure this value is less than or equal to 250\"]}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia 2023-11-23 explore models.ipynb Cell 29\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y115sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m summarize_pipeline \u001b[39m=\u001b[39m Pipeline()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y115sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m summarize_pipeline\u001b[39m.\u001b[39madd_node(component\u001b[39m=\u001b[39mprompt_node, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPromptNode\u001b[39m\u001b[39m\"\u001b[39m, inputs\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mQuery\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y115sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m output \u001b[39m=\u001b[39m summarize_pipeline\u001b[39m.\u001b[39;49mrun(query\u001b[39m=\u001b[39;49msystem_message, documents\u001b[39m=\u001b[39;49msaved_document_store\u001b[39m.\u001b[39;49mget_all_documents())\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y115sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m output_dict[iteration] \u001b[39m=\u001b[39m output\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y115sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m output\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:574\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    571\u001b[0m     \u001b[39m# The input might be a really large object with thousands of embeddings.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[39m# If you really want to see it, raise the log level.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mException while running node \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with input \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, node_id, node_input)\n\u001b[0;32m--> 574\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException while running node \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnode_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mEnable debug logging to see the data that was passed when the pipeline failed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    577\u001b[0m queue\u001b[39m.\u001b[39mpop(node_id)\n\u001b[1;32m    578\u001b[0m \u001b[39m#\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Exception while running node 'PromptNode': HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":[\"Error in `parameters.max_new_tokens`: ensure this value is less than or equal to 250\"]}\nEnable debug logging to see the data that was passed when the pipeline failed."
     ]
    }
   ],
   "source": [
    "\n",
    "summarize_pipeline = Pipeline()\n",
    "\n",
    "summarize_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Query\"])\n",
    "\n",
    "output = summarize_pipeline.run(query=system_message, documents=saved_document_store.get_all_documents())\n",
    "output_dict[iteration] = output\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try again with fewer tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = iteration\n",
    "model_name = models_list[3]\n",
    "max_length = 250\n",
    "system_message = \"\"\"\n",
    "Summarize the messages to create a Frequently Asked Questions document.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate( # https://docs.haystack.deepset.ai/docs/prompt_node#prompttemplates\n",
    "    prompt='{query}\\n\\n Messages: {join(documents)} \\n\\nSummary: '\n",
    ")\n",
    "prompt_dict[iteration] = prompt\n",
    "\n",
    "prompt_node = PromptNode( # https://docs.haystack.deepset.ai/reference/prompt-node-api # https://docs.haystack.deepset.ai/docs/prompt_node#in-a-pipeline\n",
    "    model_name, # Default is \"google/flan-t5-base\"\n",
    "    api_key=hf_access_token, \n",
    "    max_length=max_length, # The maximum number of tokens the generated text output can have,\n",
    "    default_prompt_template=prompt,\n",
    "    )\n",
    "prompt_node_dict[iteration] = prompt_node\n",
    "system_message_dict[iteration] = system_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "The prompt has been truncated from 3053 tokens to 774 tokens so that the prompt length and answer length (250 tokens) fit within the max token limit (1024 tokens). Shorten the prompt to prevent it from being cut off.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Exception while running node 'PromptNode': HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":\"The following `model_kwargs` are not used by the model: ['return_full_text', 'stop', 'watermark', 'details'] (note: typos in the generate arguments will also show up in this list)\",\"warnings\":[\"There was an inference error: The following `model_kwargs` are not used by the model: ['return_full_text', 'stop', 'watermark', 'details'] (note: typos in the generate arguments will also show up in this list)\",\"Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\"]}\nEnable debug logging to see the data that was passed when the pipeline failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:237\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer._post\u001b[0;34m(self, data, stream, attempts, status_codes_to_retry, timeout)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     response \u001b[39m=\u001b[39m request_with_retry(\n\u001b[1;32m    238\u001b[0m         method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    239\u001b[0m         status_codes_to_retry\u001b[39m=\u001b[39;49mstatus_codes_to_retry,\n\u001b[1;32m    240\u001b[0m         attempts\u001b[39m=\u001b[39;49mattempts,\n\u001b[1;32m    241\u001b[0m         url\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl,\n\u001b[1;32m    242\u001b[0m         headers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    243\u001b[0m         json\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    244\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    245\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    247\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/utils/requests_utils.py:93\u001b[0m, in \u001b[0;36mrequest_with_retry\u001b[0;34m(attempts, status_codes_to_retry, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m# We raise here too in case the request failed with a status code that\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m# won't trigger a retry, this way the call will still cause an explicit exception\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m res\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/philschmid/flan-t5-base-samsum",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHuggingFaceInferenceError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:567\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    566\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 567\u001b[0m node_output, stream_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_node(node_id, node_input)\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_debug\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m node_output \u001b[39mand\u001b[39;00m node_id \u001b[39min\u001b[39;00m node_output[\u001b[39m\"\u001b[39m\u001b[39m_debug\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:469\u001b[0m, in \u001b[0;36mPipeline._run_node\u001b[0;34m(self, node_id, node_input)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_node\u001b[39m(\u001b[39mself\u001b[39m, node_id: \u001b[39mstr\u001b[39m, node_input: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Dict, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph\u001b[39m.\u001b[39;49mnodes[node_id][\u001b[39m\"\u001b[39;49m\u001b[39mcomponent\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49m_dispatch_run(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnode_input)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:201\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mThe Pipelines call this method when run() is executed. This method in turn executes the _dispatch_run_general()\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39mmethod with the correct run method.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_run_general(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/base.py:245\u001b[0m, in \u001b[0;36mBaseComponent._dispatch_run_general\u001b[0;34m(self, run_method, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         run_inputs[key] \u001b[39m=\u001b[39m value\n\u001b[0;32m--> 245\u001b[0m output, stream \u001b[39m=\u001b[39m run_method(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrun_params)\n\u001b[1;32m    247\u001b[0m \u001b[39m# Collect debug information\u001b[39;00m\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:310\u001b[0m, in \u001b[0;36mPromptNode.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, invocation_context, prompt_template, generation_kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m invocation_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare(\n\u001b[1;32m    307\u001b[0m     query, file_paths, labels, documents, meta, invocation_context, prompt_template, generation_kwargs\n\u001b[1;32m    308\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minvocation_context, prompt_collector\u001b[39m=\u001b[39;49mprompt_collector)\n\u001b[1;32m    312\u001b[0m prompt_template_resolved: PromptTemplate \u001b[39m=\u001b[39m invocation_context\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:138\u001b[0m, in \u001b[0;36mPromptNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_template\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt(prompt_template, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_node.py:167\u001b[0m, in \u001b[0;36mPromptNode.prompt\u001b[0;34m(self, prompt_template, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mPrompt being sent to LLM with prompt \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m and kwargs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, prompt, kwargs_copy)\n\u001b[0;32m--> 167\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt_model\u001b[39m.\u001b[39;49minvoke(prompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_copy)\n\u001b[1;32m    168\u001b[0m results\u001b[39m.\u001b[39mextend(output)\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/prompt_model.py:113\u001b[0m, in \u001b[0;36mPromptModel.invoke\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mTakes in a prompt and returns a list of responses using the underlying invocation layer.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m:return: A list of model-generated responses for the prompt or prompts.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_invocation_layer\u001b[39m.\u001b[39;49minvoke(prompt\u001b[39m=\u001b[39;49mprompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:173\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer.invoke\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m    156\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbest_of\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    157\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdetails\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdetails\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwatermark\u001b[39m\u001b[39m\"\u001b[39m: kwargs_with_defaults\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mwatermark\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m    172\u001b[0m }\n\u001b[0;32m--> 173\u001b[0m response: requests\u001b[39m.\u001b[39mResponse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    174\u001b[0m     data\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt, \u001b[39m\"\u001b[39;49m\u001b[39mparameters\u001b[39;49m\u001b[39m\"\u001b[39;49m: params, \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream}, stream\u001b[39m=\u001b[39;49mstream\n\u001b[1;32m    175\u001b[0m )\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/nodes/prompt/invocation_layer/hugging_face_inference.py:254\u001b[0m, in \u001b[0;36mHFInferenceEndpointInvocationLayer._post\u001b[0;34m(self, data, stream, attempts, status_codes_to_retry, timeout)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[39mraise\u001b[39;00m HuggingFaceInferenceUnauthorizedError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI key is invalid: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mraise\u001b[39;00m HuggingFaceInferenceError(\n\u001b[1;32m    255\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHuggingFace Inference returned an error.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStatus code: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mResponse body: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         status_code\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mstatus_code,  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mHuggingFaceInferenceError\u001b[0m: HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":\"The following `model_kwargs` are not used by the model: ['return_full_text', 'stop', 'watermark', 'details'] (note: typos in the generate arguments will also show up in this list)\",\"warnings\":[\"There was an inference error: The following `model_kwargs` are not used by the model: ['return_full_text', 'stop', 'watermark', 'details'] (note: typos in the generate arguments will also show up in this list)\",\"Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\"]}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia 2023-11-23 explore models.ipynb Cell 32\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m summarize_pipeline \u001b[39m=\u001b[39m Pipeline()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m summarize_pipeline\u001b[39m.\u001b[39madd_node(component\u001b[39m=\u001b[39mprompt_node, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPromptNode\u001b[39m\u001b[39m\"\u001b[39m, inputs\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mQuery\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m output \u001b[39m=\u001b[39m summarize_pipeline\u001b[39m.\u001b[39;49mrun(query\u001b[39m=\u001b[39;49msystem_message, documents\u001b[39m=\u001b[39;49msaved_document_store\u001b[39m.\u001b[39;49mget_all_documents())\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m output_dict[iteration] \u001b[39m=\u001b[39m output\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/silvhua/repositories/solarathon-faq-creator/notebooks/silvia%202023-11-23%20explore%20models.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m output\n",
      "File \u001b[0;32m~/solarathon/lib/python3.10/site-packages/haystack/pipelines/base.py:574\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    571\u001b[0m     \u001b[39m# The input might be a really large object with thousands of embeddings.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[39m# If you really want to see it, raise the log level.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mException while running node \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with input \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, node_id, node_input)\n\u001b[0;32m--> 574\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException while running node \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnode_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mEnable debug logging to see the data that was passed when the pipeline failed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    577\u001b[0m queue\u001b[39m.\u001b[39mpop(node_id)\n\u001b[1;32m    578\u001b[0m \u001b[39m#\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Exception while running node 'PromptNode': HuggingFace Inference returned an error.\nStatus code: 400\nResponse body: {\"error\":\"The following `model_kwargs` are not used by the model: ['return_full_text', 'stop', 'watermark', 'details'] (note: typos in the generate arguments will also show up in this list)\",\"warnings\":[\"There was an inference error: The following `model_kwargs` are not used by the model: ['return_full_text', 'stop', 'watermark', 'details'] (note: typos in the generate arguments will also show up in this list)\",\"Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\"]}\nEnable debug logging to see the data that was passed when the pipeline failed."
     ]
    }
   ],
   "source": [
    "\n",
    "summarize_pipeline = Pipeline()\n",
    "\n",
    "summarize_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Query\"])\n",
    "\n",
    "output = summarize_pipeline.run(query=system_message, documents=saved_document_store.get_all_documents())\n",
    "output_dict[iteration] = output\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try using API request directly to hugging face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## philschmid/flan-t5-base-samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Model philschmid/flan-t5-base-samsum is currently loading',\n",
       " 'estimated_time': 39.61640548706055}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/philschmid/flan-t5-base-samsum\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_access_token}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"what is kinesiology?\",\n",
    "})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_response_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sshleifer/distilbart-cnn-12-6', 'facebook/bart-large-cnn']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Model philschmid/bart-large-cnn-samsum is currently loading',\n",
       " 'estimated_time': 130.04541015625}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def query_hugging_face(model_name, input):\n",
    "\n",
    "    API_URL = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {hf_access_token}\"}\n",
    "    payload = {\"inputs\": input}\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "API_URL = \"https://api-inference.huggingface.co/models/philschmid/flan-t5-base-samsum\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_access_token}\"}\n",
    "\t\n",
    "model = 2\n",
    "input = \"what is kinesiology?\"\n",
    "hf_response_dict[models_list[model]] = query_hugging_face(models_list[model], input)\n",
    "hf_response_dict[models_list[model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'what is kinesiology?\\nA: Kinesiology is the scientific study of movement and its effects on the human body'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
    "input = \"what is kinesiology?\"\n",
    "hf_response_dict[model] = query_hugging_face(model, input)\n",
    "hf_response_dict[model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(output['results']))\n",
    "print(output['results'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solarathon",
   "language": "python",
   "name": "solarathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
