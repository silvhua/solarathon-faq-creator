{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.nodes import TextConverter\n",
    "from haystack.nodes import PreProcessor\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
    "from haystack.nodes import EmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_dict = dict()\n",
    "file_converter_dict = dict() \n",
    "preprocessor_dict = dict()\n",
    "document_store_dict = dict()\n",
    "prompt_node_dict = dict()\n",
    "prompt_node_dict = dict()\n",
    "output_dict = dict()\n",
    "system_message_dict = dict()\n",
    "prompt_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('openai_api_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads\n",
    "embedding_models_list = [\n",
    "    'sentence-transformers/all-mpnet-base-v2',\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RAW JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json(filename, filepath):\n",
    "    \"\"\"\n",
    "    Load a JSON file using specified file path copied from windows file explorer.\n",
    "    Back slashes in file path will be converted to forward slashes.\n",
    "\n",
    "    Arguments:\n",
    "    - filepath (raw string): Use the format r'<path>'.\n",
    "    - filename (string).\n",
    "    \"\"\"\n",
    "    filename = f'{filepath}/'.replace('\\\\','/')+filename\n",
    "    with open(filename) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "filepath = '../data/private/'\n",
    "filename = 'Discord_all_messages.json'\n",
    "messages = load_json(filename, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2249\n"
     ]
    }
   ],
   "source": [
    "def filter_messages(messages):\n",
    "    filtered_messages = []\n",
    "    for message in messages:\n",
    "        filtered_message = {\n",
    "            'id': message['id'],\n",
    "            'author_id': message['author_id'],\n",
    "            'content': message['content'],\n",
    "            'reference_id': message['reference_id']\n",
    "        }\n",
    "        filtered_messages.append(filtered_message)\n",
    "    return filtered_messages\n",
    "\n",
    "# messages = [...]  # Your list of dictionaries\n",
    "filtered_messages = filter_messages(messages)\n",
    "print(len(filtered_messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'author_id', 'content', 'reference_id'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_messages[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save filtered messages as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved as JSON: truncated_Discord_messages_2023-11-24_1259.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def save_to_json(obj, filename=None, description='Discord_messages_json', append_version=1,\n",
    "    path='../data'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Save Python object as a JSON file.\n",
    "    Parameters:\n",
    "    - obj: Python object to be saved.\n",
    "    - filename: Root of the filename.\n",
    "    - path (raw string): Use the format r'<path>'. If None, file is saved in same directory as script.\n",
    "    - append_version (bool): If true, append date and time to end of filename.\n",
    "    \"\"\"\n",
    "    if description:\n",
    "        filename = f'{description}_{datetime.now().strftime(\"%Y-%m-%d_%H%M\")}'\n",
    "        append_version = False\n",
    "    elif filename == None:\n",
    "        filename = f'{datetime.now().strftime(\"%Y-%m-%d_%H%M\")}_outputs'\n",
    "        append_version = False\n",
    "    if path:\n",
    "        path = f'{path}/'.replace('\\\\','/')\n",
    "    if append_version:\n",
    "        filename += f'_{datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")}'\n",
    "    filename += '.json'\n",
    "    with open(path+filename, 'w') as f:\n",
    "        json.dump(obj, f)\n",
    "    print(f'Object saved as JSON: {filename}')\n",
    "\n",
    "\n",
    "description = 'truncated_Discord_messages'\n",
    "save_path = '../data/testing_2023-11-24/'\n",
    "save_to_json(filtered_messages[:100], description=description, path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 7\n",
    "file_converter = TextConverter() # https://docs.haystack.deepset.ai/docs/file_converters\n",
    "file_converter_dict[iteration] = file_converter\n",
    "\n",
    "preprocessor = PreProcessor( # https://docs.haystack.deepset.ai/docs/preprocessor\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "  \tremove_substrings=None,\n",
    "    split_by='passage', # Unit for splitting the document. Can be \"word\", \"sentence\", or \"passage\". Set to None to disable splitting.\n",
    "    split_length=100,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    split_overlap=0,\n",
    "  \tmax_chars_check = 500000\n",
    ")\n",
    "preprocessor_dict[iteration] = preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created timestamp string: 2023-11-24_1410\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def append_timestamp(string, ext=None):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "    if ext:\n",
    "        return f'{string}_{timestamp}.{ext}'\n",
    "    else:\n",
    "        return f'{string}_{timestamp}' \n",
    "\n",
    "def create_timestamp():\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "    print(f'Created timestamp string: {timestamp}')\n",
    "    return timestamp\n",
    "\n",
    "timestamp_string = create_timestamp()\n",
    "\n",
    "index_filename = 'journal_article_index'+ timestamp_string\n",
    "config_filename = 'journal_article_config'+ timestamp_string\n",
    "faiss_filename = 'faiss_document_store'+ timestamp_string\n",
    "path = '../data/testing_2023-11-24/'\n",
    "document_store = FAISSDocumentStore( # https://docs.haystack.deepset.ai/reference/document-store-api#faissdocumentstore\n",
    "    sql_url=f\"sqlite:///{path}{faiss_filename}.db\",\n",
    "    # embedding_dim=384,\n",
    "    faiss_index_factory_str=\"Flat\"\n",
    "    )\n",
    "document_store_dict[iteration] = document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU - Number of GPUs: 0\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "retriever = EmbeddingRetriever( # https://docs.haystack.deepset.ai/reference/retriever-api\n",
    "    document_store=document_store,\n",
    "    embedding_model=embedding_models_list[0],\n",
    "    model_format=\"sentence_transformers\",\n",
    "    top_k = 100\n",
    ")\n",
    "retriever_dict[iteration] = retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting files: 100%|██████████| 1/1 [00:00<00:00, 39.11it/s]\n",
      "Preprocessing: 100%|██████████| 1/1 [00:00<00:00, 87.13docs/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623f60b9a2ac494bb64e291ee76339bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:00, 140012.22it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n",
      "Document content type: <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_pipeline(data_filename, data_path):\n",
    "    p = Pipeline()\n",
    "    p.add_node(component=file_converter, name=\"FileConverter\", inputs=[\"File\"])\n",
    "    p.add_node(component=preprocessor, name=\"PreProcessor\", inputs=[\"FileConverter\"])\n",
    "    p.add_node(component=retriever, name=\"Retriever\", inputs=[\"PreProcessor\"])\n",
    "    p.add_node(component=document_store, name=\"DocumentStore\", inputs=[\"Retriever\"])\n",
    "    p.run(file_paths=[f\"{data_path if data_path else '.'}/{data_filename}\"])\n",
    "    print(f'Number of documents: {len(p.get_document_store().get_all_documents())}')\n",
    "    print(f'Document content type: {type(p.get_document_store().get_all_documents()[0].content)}') #### SH 2023-11-24 14:17 return the p object\n",
    "\n",
    "data_path = '../data/testing_2023-11-24'\n",
    "data_filename = 'truncated_Discord_messages_2023-11-24_1259.json'\n",
    "\n",
    "run_pipeline(data_filename, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.faiss -  Updating embeddings for 1 docs...\n",
      "Updating Embedding:   0%|          | 0/1 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fcac5473894823964fac4e0b4bdd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:01, 8073.55 docs/s]      \n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever)\n",
    "document_store.save(index_path=f'{path}/{index_filename}', config_path=f'{path}/{config_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    'gpt-3.5-turbo-16k',\n",
    "    'gpt-3.5-turbo-16k-0613',\n",
    "    'gpt-3.5-turbo-instruct',\n",
    "    'gpt-3.5-turbo-instruct-0914',\n",
    "    'gpt-4',\n",
    "    'gpt-4-0314',\n",
    "    'gpt-4-0613',\n",
    "    'gpt-4-1106-preview',\n",
    "    'gpt-3.5-turbo',\n",
    "    'gpt-3.5-turbo-0301',\n",
    "    'gpt-3.5-turbo-0613',\n",
    "    'gpt-3.5-turbo-1106',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading document store from ../data/testing_2023-11-24//journal_article_index2023-11-24_1410 and ../data/testing_2023-11-24//journal_article_config2023-11-24_1410.\n",
      "Document content data type: <class 'str'>\n",
      "Number of documents: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_document_store(index_filename, config_filename, path):\n",
    "    saved_document_store = FAISSDocumentStore.load(\n",
    "        index_path=f'{path}/{index_filename}', config_path=f'{path}/{config_filename}'\n",
    "        )\n",
    "    print(f'Loading document store from {path}/{index_filename} and {path}/{config_filename}.')\n",
    "    print(f'Document content data type: {type(saved_document_store.get_all_documents()[0].content)}')\n",
    "    print(f'Number of documents: {len(saved_document_store.get_all_documents())}')\n",
    "    return saved_document_store\n",
    "\n",
    "# file_timestamp = timestamp_string\n",
    "file_timestamp = '2023-11-24_1410'\n",
    "path = '../data/testing_2023-11-24/'\n",
    "index_filename = 'journal_article_index'+file_timestamp\n",
    "config_filename = 'journal_article_config'+file_timestamp\n",
    "faiss_filename = 'faiss_document_store'+file_timestamp\n",
    "# path = path\n",
    "saved_document_store = load_document_store(index_filename, config_filename, path)\n",
    "document_store = saved_document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 7.3\n",
    "model_name = models_list[0]\n",
    "max_length = 3000\n",
    "system_message = \"\"\"\n",
    "The following is a JSON array of objects containing a sequence of Discord messages. \n",
    "The messages have the following attributes:\n",
    "- id: The ID of the message.\n",
    "- author_id: The ID of the message write.\n",
    "- content: The content of the message.\n",
    "- reference_id: The ID of the parent message. If the message is not a reply, this will be null.\n",
    "    Otherwise, this value indicates that the message is a reply to the message with the specified ID.\n",
    "\n",
    "Summarize the messages to create a Frequently Asked Questions document. Return the output as a JSON array \n",
    "where each element is a question-answer pair. For example:\n",
    "[\n",
    "    {\n",
    "        \"question\": \"Question 1\",\n",
    "        \"answer\": \"Answer 1\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Question 2\",\n",
    "        \"answer\": \"Answer 2\"\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "prompt = PromptTemplate( # https://docs.haystack.deepset.ai/docs/prompt_node#prompttemplates\n",
    "    prompt='{query}\\n\\n Messages: {join(documents)} \\n\\nSummary: '\n",
    ")\n",
    "prompt_dict[iteration] = prompt\n",
    "\n",
    "prompt_node = PromptNode( # https://docs.haystack.deepset.ai/reference/prompt-node-api # https://docs.haystack.deepset.ai/docs/prompt_node#in-a-pipeline\n",
    "    model_name, api_key=openai_api_key, \n",
    "    max_length=max_length, # The maximum number of tokens the generated text output can have,\n",
    "    default_prompt_template=prompt,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0,\n",
    "        \"response_format\": { \"type\": \"json_object\" }\n",
    "        }\n",
    "    )\n",
    "prompt_node_dict[iteration] = prompt_node\n",
    "system_message_dict[iteration] = system_message\n",
    "\n",
    "# retriever = EmbeddingRetriever( # https://docs.haystack.deepset.ai/reference/retriever-api\n",
    "#     document_store=document_store,\n",
    "#     embedding_model=embedding_models_list[0],\n",
    "#     model_format=\"sentence_transformers\",\n",
    "#     top_k = 100\n",
    "# )\n",
    "# retriever_dict[iteration] = retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using retriever; using DocumentStore\n",
      "\n",
      "*Model output*: \n",
      "[\n",
      "    {\n",
      "        \"question\": \"When embedded with FastAPI, is there a different port that Solara loads or is it the same port as uvicorn?\",\n",
      "        \"answer\": \"Solara loads on the same port as uvicorn.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Why does Solara not load when deployed as a Docker image?\",\n",
      "        \"answer\": \"There may be an issue with websocket requesting jupyter widgets. Make sure you use the same browser and check the docker container logs for any errors.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Is there a reverse proxy in between Solara and the server?\",\n",
      "        \"answer\": \"Yes, there is a reverse proxy in production. Make sure to set up firewall rules as well.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"How can I make InputText multiline in Solara?\",\n",
      "        \"answer\": \"There seems to be an issue with making InputText multiline. CSS class may not work. Further assistance is recommended.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Why am I getting an error 'Cannot read properties of undefined (reading 'extend')' after updating Solara to version 1.23.0?\",\n",
      "        \"answer\": \"This issue may be related to the update. Try disabling cache and reloading the page. If the issue persists, it is recommended to seek further assistance.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What are the requirements for Solara?\",\n",
      "        \"answer\": \"Solara has a few requirements, including Altair. It is recommended to install all the required dependencies for full functionality.\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Can't load Solara after upgrading to version 1.23.0. What should I do?\",\n",
      "        \"answer\": \"If you are experiencing issues after upgrading to version 1.23.0, try reverting back to version 1.22.0. It is recommended to follow the upgrade steps provided or seek further assistance.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def run_summarization(system_message, document_store=None, retriever=None, prompt_node=prompt_node, use_retriever=False):\n",
    "    summarize_pipeline = Pipeline()\n",
    "    if use_retriever:\n",
    "        print(f'Using retriever')\n",
    "        summarize_pipeline.add_node(component=retriever, name=\"RetrieverNode\", inputs=[\"Query\"])\n",
    "        summarize_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"RetrieverNode\"])\n",
    "        output = summarize_pipeline.run(query=system_message, params={\"RetrieverNode\":{\"top_k\": 100}})\n",
    "    else:\n",
    "        print(f'Not using retriever; using DocumentStore')\n",
    "        summarize_pipeline.add_node(component=prompt_node, name=\"PromptNode\", inputs=[\"Query\"])\n",
    "        output = summarize_pipeline.run(query=system_message, documents=document_store.get_all_documents())\n",
    "    print(f\"\\n*Model output*: \\n{output['results'][0]}\")\n",
    "    return output\n",
    "\n",
    "\n",
    "output = run_summarization(\n",
    "    system_message, \n",
    "    document_store=document_store, \n",
    "    retriever=None, \n",
    "    prompt_node=prompt_node, use_retriever=False\n",
    "    )\n",
    "output_dict[iteration] = output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solarathon",
   "language": "python",
   "name": "solarathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
